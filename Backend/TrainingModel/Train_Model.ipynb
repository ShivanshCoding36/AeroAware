{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz_fOmwOOkn1",
        "outputId": "29302bb1-8600-4f80-ef20-d406746f84a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openaq in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (from openaq) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->openaq) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->openaq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->openaq) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->openaq) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx==0.28.1->openaq) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx==0.28.1->openaq) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx==0.28.1->openaq) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openaq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "lat, lon = 28.31733, 76.91603  # Manesar\n",
        "url = f\"https://power.larc.nasa.gov/api/temporal/hourly/point\"\n",
        "params = {\n",
        "    \"parameters\": \"T2M,RH2M,PRECTOTCORR\",\n",
        "    \"community\": \"RE\",\n",
        "    \"longitude\": lon,\n",
        "    \"latitude\": lat,\n",
        "    \"format\": \"JSON\",\n",
        "    \"start\": \"20240901\",\n",
        "    \"end\": \"20250901\"\n",
        "}\n",
        "\n",
        "r = requests.get(url, params=params)\n",
        "data = r.json()[\"properties\"][\"parameter\"]\n",
        "\n",
        "df_weather = pd.DataFrame({\n",
        "    \"datetime\": list(data[\"T2M\"].keys()),\n",
        "    \"temperature\": list(data[\"T2M\"].values()),\n",
        "    \"humidity\": list(data[\"RH2M\"].values()),\n",
        "    \"precipitation\": list(data[\"PRECTOTCORR\"].values())\n",
        "})\n",
        "\n",
        "df_weather.to_csv(\"weather_data.csv\", index=False)\n",
        "print(df_weather.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKlRQGz3YaFH",
        "outputId": "009d1d15-21dc-4766-dfcc-ac1ba573bb1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     datetime  temperature  humidity  precipitation\n",
            "0  2024090100        28.09     75.37            0.0\n",
            "1  2024090101        27.71     76.67            0.0\n",
            "2  2024090102        27.27     79.20            0.0\n",
            "3  2024090103        26.74     81.70            0.0\n",
            "4  2024090104        26.30     84.17            0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "4FFx_AgZZuXC",
        "outputId": "b9b66843-e209-4c51-a30b-01a356dab14b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime         8784\n",
              "temperature      8784\n",
              "humidity         8784\n",
              "precipitation    8784\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>8784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature</th>\n",
              "      <td>8784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>humidity</th>\n",
              "      <td>8784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precipitation</th>\n",
              "      <td>8784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------------\n",
        "API_KEY = \"72dd209011465d910f7b44d557d8764f26bfeb1d8306bd00bef2781308e44913\"\n",
        "SENSOR_ID = \"10326358\"  # Example sensor ID\n",
        "PARAMETER = \"pm25\"\n",
        "LIMIT = 1000\n",
        "START_DATE = \"2024-09-01\"\n",
        "END_DATE = \"2025-09-01\"\n",
        "\n",
        "HEADERS = {\"X-API-Key\": API_KEY}\n",
        "BASE_URL = f\"https://api.openaq.org/v3/sensors/{SENSOR_ID}/hours\"\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Fetch all PM2.5 data (in chunks)\n",
        "# -------------------------------\n",
        "all_results = []\n",
        "page = 1\n",
        "\n",
        "print(\"üîÑ Fetching hourly PM2.5 data from OpenAQ...\")\n",
        "\n",
        "while True:\n",
        "    params = {\n",
        "        \"date_from\": START_DATE,\n",
        "        \"date_to\": END_DATE,\n",
        "        \"limit\": LIMIT,\n",
        "        \"page\": page\n",
        "    }\n",
        "\n",
        "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"‚ùå Error {response.status_code}: {response.text}\")\n",
        "        break\n",
        "\n",
        "    data = response.json()\n",
        "    results = data.get(\"results\", [])\n",
        "    if not results:\n",
        "        print(f\"‚úÖ No more data. Finished at page {page}.\")\n",
        "        break\n",
        "\n",
        "    all_results.extend(results)\n",
        "    print(f\"üì¶ Page {page}: fetched {len(results)} entries (total = {len(all_results)})\")\n",
        "\n",
        "    page += 1\n",
        "    time.sleep(1)  # avoid rate limit\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Convert to DataFrame\n",
        "# -------------------------------\n",
        "if not all_results:\n",
        "    print(\"‚ö†Ô∏è No results found. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "aq_data = pd.DataFrame(all_results)\n",
        "\n",
        "# Parse datetime and value columns\n",
        "aq_data[\"datetime\"] = pd.to_datetime(aq_data[\"period\"].apply(lambda x: x[\"datetimeFrom\"][\"utc\"]))\n",
        "aq_data[\"pm25\"] = aq_data[\"value\"]\n",
        "aq_data = aq_data[[\"datetime\", \"pm25\"]]\n",
        "\n",
        "# Save raw PM2.5 data\n",
        "aq_data.to_csv(\"pm25_data.csv\", index=False)\n",
        "print(f\"üíæ Saved {len(aq_data)} PM2.5 entries ‚Üí pm25_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "yQ74wAC4aarX",
        "outputId": "ae1b2a79-7d46-43a4-8475-94132a3c0bba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Fetching hourly PM2.5 data from OpenAQ...\n",
            "üì¶ Page 1: fetched 1000 entries (total = 1000)\n",
            "üì¶ Page 2: fetched 1000 entries (total = 2000)\n",
            "üì¶ Page 3: fetched 1000 entries (total = 3000)\n",
            "üì¶ Page 4: fetched 1000 entries (total = 4000)\n",
            "üì¶ Page 5: fetched 1000 entries (total = 5000)\n",
            "üì¶ Page 6: fetched 1000 entries (total = 6000)\n",
            "üì¶ Page 7: fetched 1000 entries (total = 7000)\n",
            "üì¶ Page 8: fetched 1000 entries (total = 8000)\n",
            "üì¶ Page 9: fetched 327 entries (total = 8327)\n",
            "‚úÖ No more data. Finished at page 10.\n",
            "üíæ Saved 8327 PM2.5 entries ‚Üí pm25_data.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MergeError",
          "evalue": "incompatible merge keys [0] datetime64[ns, UTC] and dtype('<M8[ns]'), must be the same type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2444694519.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Merge nearest timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m df_merged = pd.merge_asof(\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0maq_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mdf_weather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;36m4\u001b[0m \u001b[0;36m2016\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m00.048\u001b[0m   \u001b[0mAAPL\u001b[0m   \u001b[0;36m98.00\u001b[0m       \u001b[0;36m100\u001b[0m     \u001b[0mNaN\u001b[0m     \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \"\"\"\n\u001b[0;32m--> 691\u001b[0;31m     op = _AsOfMerge(\n\u001b[0m\u001b[1;32m    692\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m         _OrderedMerge.__init__(\n\u001b[0m\u001b[1;32m   2000\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, suffixes, fill_method, how)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     ) -> None:\n\u001b[1;32m   1910\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         _MergeOperation.__init__(\n\u001b[0m\u001b[1;32m   1912\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_require_matching_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_require_matching_dtypes\u001b[0;34m(self, left_join_keys, right_join_keys)\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;31m# validate index types are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_join_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m             \u001b[0m_check_dtype_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_check_dtype_match\u001b[0;34m(left, right, i)\u001b[0m\n\u001b[1;32m   2118\u001b[0m                         \u001b[0;34mf\"{repr(right.dtype)}, must be the same type\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m                     )\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;31m# validate index types are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMergeError\u001b[0m: incompatible merge keys [0] datetime64[ns, UTC] and dtype('<M8[ns]'), must be the same type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pmData= pd.read_csv('pm25_data.csv')\n",
        "pmData.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sAs1kTISi7Ds",
        "outputId": "95da53e9-7afe-43a5-d2d9-f4c15224655e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    datetime  pm25\n",
              "0  2024-08-20 06:00:00+00:00  10.1\n",
              "1  2024-08-20 07:00:00+00:00  11.1\n",
              "2  2024-08-20 09:00:00+00:00  11.9\n",
              "3  2024-08-20 10:00:00+00:00  12.3\n",
              "4  2024-08-20 11:00:00+00:00  12.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5550ed9f-649b-4031-b5f1-ffd41f34310c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>pm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-08-20 06:00:00+00:00</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-08-20 07:00:00+00:00</td>\n",
              "      <td>11.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-08-20 09:00:00+00:00</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-08-20 10:00:00+00:00</td>\n",
              "      <td>12.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-08-20 11:00:00+00:00</td>\n",
              "      <td>12.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5550ed9f-649b-4031-b5f1-ffd41f34310c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5550ed9f-649b-4031-b5f1-ffd41f34310c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5550ed9f-649b-4031-b5f1-ffd41f34310c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa6322be-d2e1-4aa8-a34d-8d3abc1fc1e0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa6322be-d2e1-4aa8-a34d-8d3abc1fc1e0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa6322be-d2e1-4aa8-a34d-8d3abc1fc1e0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pmData",
              "summary": "{\n  \"name\": \"pmData\",\n  \"rows\": 8327,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8327,\n        \"samples\": [\n          \"2025-02-09 01:30:00+00:00\",\n          \"2024-11-11 19:30:00+00:00\",\n          \"2025-07-21 15:30:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pm25\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.976180691711015,\n        \"min\": 6.5,\n        \"max\": 259.0,\n        \"num_unique_values\": 1003,\n        \"samples\": [\n          112.0,\n          166.0,\n          90.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pmData= pd.read_csv('weather_data.csv')\n",
        "pmData.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IGbbkI1YjBqR",
        "outputId": "714e8841-7743-4320-a432-d68c35986713"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     datetime  temperature  humidity  precipitation\n",
              "0  2024090100        28.09     75.37            0.0\n",
              "1  2024090101        27.71     76.67            0.0\n",
              "2  2024090102        27.27     79.20            0.0\n",
              "3  2024090103        26.74     81.70            0.0\n",
              "4  2024090104        26.30     84.17            0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c366a4f-79bf-417b-8ee2-d159293dd65f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>precipitation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024090100</td>\n",
              "      <td>28.09</td>\n",
              "      <td>75.37</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024090101</td>\n",
              "      <td>27.71</td>\n",
              "      <td>76.67</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024090102</td>\n",
              "      <td>27.27</td>\n",
              "      <td>79.20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024090103</td>\n",
              "      <td>26.74</td>\n",
              "      <td>81.70</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024090104</td>\n",
              "      <td>26.30</td>\n",
              "      <td>84.17</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c366a4f-79bf-417b-8ee2-d159293dd65f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c366a4f-79bf-417b-8ee2-d159293dd65f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c366a4f-79bf-417b-8ee2-d159293dd65f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3663c4cd-ae64-4485-b83d-99a41b1f0c06\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3663c4cd-ae64-4485-b83d-99a41b1f0c06')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3663c4cd-ae64-4485-b83d-99a41b1f0c06 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pmData",
              "summary": "{\n  \"name\": \"pmData\",\n  \"rows\": 8784,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 443762,\n        \"min\": 2024090100,\n        \"max\": 2025090123,\n        \"num_unique_values\": 8784,\n        \"samples\": [\n          2025052501,\n          2024110200,\n          2025053111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.43520222342476,\n        \"min\": 3.72,\n        \"max\": 46.21,\n        \"num_unique_values\": 3150,\n        \"samples\": [\n          45.89,\n          18.63,\n          8.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.27416480571487,\n        \"min\": 3.04,\n        \"max\": 100.0,\n        \"num_unique_values\": 5653,\n        \"samples\": [\n          18.11,\n          66.47,\n          19.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precipitation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.75934279254155,\n        \"min\": 0.0,\n        \"max\": 890.88,\n        \"num_unique_values\": 1161,\n        \"samples\": [\n          11.38,\n          25.57,\n          6.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Merge with weather data\n",
        "# -------------------------------\n",
        "try:\n",
        "    df_weather = pd.read_csv(\"weather_data.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è weather_data.csv not found. Please place your NASA weather file in the same folder.\")\n",
        "    exit()\n",
        "\n",
        "# Parse datetime for both datasets\n",
        "aq_data[\"datetime\"] = pd.to_datetime(aq_data[\"datetime\"]).dt.tz_localize(None)\n",
        "df_weather[\"datetime\"] = pd.to_datetime(df_weather[\"datetime\"], format=\"%Y%m%d%H\").dt.tz_localize(None)\n",
        "\n",
        "# Merge nearest timestamps\n",
        "df_merged = pd.merge_asof(\n",
        "    aq_data.sort_values(\"datetime\"),\n",
        "    df_weather.sort_values(\"datetime\"),\n",
        "    on=\"datetime\",\n",
        "    direction=\"nearest\",\n",
        "    tolerance=pd.Timedelta(\"1H\")  # allow up to 1-hour difference\n",
        ")\n",
        "\n",
        "# Drop rows missing PM2.5 or weather info\n",
        "df_merged = df_merged.dropna(subset=[\"pm25\", \"temperature\", \"humidity\", \"precipitation\"], how=\"any\")\n",
        "\n",
        "# Save merged dataset\n",
        "df_merged.to_csv(\"air_quality_weather.csv\", index=False)\n",
        "print(f\"‚úÖ Final merged dataset saved ‚Üí air_quality_weather.csv ({len(df_merged)} rows)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiU7XrHyjL_j",
        "outputId": "515ed7aa-cb26-41c2-ebab-ff682d99a467"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Final merged dataset saved ‚Üí air_quality_weather.csv (7456 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3135047614.py:20: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
            "  tolerance=pd.Timedelta(\"1H\")  # allow up to 1-hour difference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Load PM2.5 data\n",
        "# -------------------------------\n",
        "pm_df = pd.read_csv(\"pm25_data.csv\")\n",
        "pm_df[\"datetime\"] = pd.to_datetime(pm_df[\"datetime\"]).dt.tz_localize(None)\n",
        "pm_df = pm_df.sort_values(\"datetime\")\n",
        "\n",
        "# Rename PM2.5 column for clarity\n",
        "pm_df.rename(columns={\"value\": \"pm25\"}, inplace=True, errors=\"ignore\")\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Load weather data\n",
        "# -------------------------------\n",
        "weather_df = pd.read_csv(\"weather_data.csv\")\n",
        "weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"], format=\"%Y%m%d%H\").dt.tz_localize(None)\n",
        "weather_df = weather_df.sort_values(\"datetime\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Merge by nearest timestamp (within 1 hour)\n",
        "# -------------------------------\n",
        "merged_df = pd.merge_asof(\n",
        "    pm_df.sort_values(\"datetime\"),\n",
        "    weather_df.sort_values(\"datetime\"),\n",
        "    on=\"datetime\",\n",
        "    direction=\"nearest\",\n",
        "    tolerance=pd.Timedelta(\"1H\")\n",
        ")\n",
        "\n",
        "# Drop rows with missing weather or PM2.5\n",
        "merged_df = merged_df.dropna(subset=[\"pm25\", \"temperature\", \"humidity\", \"precipitation\"], how=\"any\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Create next-hour PM2.5 column\n",
        "# -------------------------------\n",
        "merged_df[\"pm25_next\"] = merged_df[\"pm25\"].shift(-1)\n",
        "\n",
        "# Drop last row (no next-hour value)\n",
        "merged_df = merged_df.dropna(subset=[\"pm25_next\"])\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Rename columns clearly\n",
        "# -------------------------------\n",
        "merged_df = merged_df.rename(columns={\"pm25\": \"pm25_current\"})\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Save final dataset\n",
        "# -------------------------------\n",
        "merged_df.to_csv(\"air_quality_forecast_dataset.csv\", index=False)\n",
        "\n",
        "print(f\"‚úÖ Final dataset saved ‚Üí air_quality_forecast_dataset.csv ({len(merged_df)} rows)\")\n",
        "print(\"üìä Columns:\", list(merged_df.columns))\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ftPJz_PmpxR",
        "outputId": "3fd17f16-b526-4447-cce2-76be4279f69f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Final dataset saved ‚Üí air_quality_forecast_dataset.csv (7455 rows)\n",
            "üìä Columns: ['datetime', 'pm25_current', 'temperature', 'humidity', 'precipitation', 'pm25_next']\n",
            "               datetime  pm25_current  temperature  humidity  precipitation  \\\n",
            "175 2024-08-31 23:00:00          32.1        28.09     75.37            0.0   \n",
            "176 2024-09-01 00:00:00          39.2        28.09     75.37            0.0   \n",
            "177 2024-09-01 01:00:00          23.8        27.71     76.67            0.0   \n",
            "178 2024-09-01 02:00:00          20.8        27.27     79.20            0.0   \n",
            "179 2024-09-01 03:00:00          20.0        26.74     81.70            0.0   \n",
            "\n",
            "     pm25_next  \n",
            "175       39.2  \n",
            "176       23.8  \n",
            "177       20.8  \n",
            "178       20.0  \n",
            "179       18.9  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1322929985.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
            "  tolerance=pd.Timedelta(\"1H\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isna().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "btMCDDIRnjFp",
        "outputId": "a816c661-c546-4eb5-83c5-ba2ddeb18a63"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime         7455\n",
              "pm25_current     7455\n",
              "temperature      7455\n",
              "humidity         7455\n",
              "precipitation    7455\n",
              "pm25_next        7455\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pm25_current</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>humidity</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precipitation</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pm25_next</th>\n",
              "      <td>7455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "# For demonstration, we combine OpenAQ + weather data\n",
        "# Replace this CSV with actual collected/merged data\n",
        "# Columns: ['pm25', 'temperature', 'humidity', 'precipitation']\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]  # features\n",
        "y = df['pm25_next']  # target (next hour/day PM2.5 prediction)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Train model\n",
        "# -------------------------------\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate\n",
        "# -------------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save trained model\n",
        "# -------------------------------\n",
        "joblib.dump(model, \"forecast_model.pkl\")\n",
        "print(\"Model saved to forecast_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_An_ltXtnEqq",
        "outputId": "bbac0918-5149-4c18-f077-5b4f9747e03d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 4.42\n",
            "RMSE: 67.11\n",
            "Model saved to forecast_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci_CivTboFSA",
        "outputId": "67ddb887-6dbd-4e30-c06f-176a02b03983"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# == Option 1: Tuned Random Forest Regressor ==\n",
        "print(\"--- Tuning Random Forest ---\")\n",
        "rf_param_dist = {\n",
        "    'n_estimators': randint(100, 500),      # Number of trees in the forest\n",
        "    'max_depth': randint(10, 50),           # Maximum depth of the tree\n",
        "    'min_samples_split': randint(2, 20),    # Minimum samples required to split a node\n",
        "    'min_samples_leaf': randint(1, 20),     # Minimum samples required at a leaf node\n",
        "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider at every split\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_distributions=rf_param_dist,\n",
        "    n_iter=50,       # Number of parameter settings that are sampled\n",
        "    cv=5,            # 5-fold cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1        # Use all available cores\n",
        ")\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # RMSE is the square root of MSE\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model1.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V7rjHyMon7E",
        "outputId": "c567f8b9-6661-47b1-f84f-a884bb8f201c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tuning Random Forest ---\n",
            "Starting hyperparameter search...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "Best Hyperparameters Found:\n",
            "{'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 13, 'n_estimators': 413}\n",
            "\n",
            "--- Evaluating Best Model ---\n",
            "MAE: 4.38\n",
            "RMSE: 8.07\n",
            "\n",
            "Tuned model saved to tuned_forecast_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# # == Option 2: Tuned XGBoost Regressor ==\n",
        "print(\"--- Tuning XGBoost ---\")\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': randint(3, 15),\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],         # Fraction of training data to use per tree\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]   # Fraction of features to use per tree\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "    param_distributions=xgb_param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # RMSE is the square root of MSE\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model2.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xuLML1zowE9",
        "outputId": "43a2dc09-f682-4a86-c07e-27129ba12003"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tuning XGBoost ---\n",
            "Starting hyperparameter search...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "Best Hyperparameters Found:\n",
            "{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 413, 'subsample': 0.8}\n",
            "\n",
            "--- Evaluating Best Model ---\n",
            "MAE: 4.42\n",
            "RMSE: 8.07\n",
            "\n",
            "Tuned model saved to tuned_forecast_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# == Option 3: Tuned LightGBM Regressor ==\n",
        "print(\"--- Tuning LightGBM ---\")\n",
        "lgb_param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'num_leaves': randint(20, 100),            # Main driver of model complexity\n",
        "    'max_depth': randint(5, 30),\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=lgb.LGBMRegressor(random_state=42),\n",
        "    param_distributions=lgb_param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # RMSE is the square root of MSE\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model3.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My1Iz3xKow7d",
        "outputId": "4dd82e8d-6deb-405c-8e20-ea9047c81ffc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tuning LightGBM ---\n",
            "Starting hyperparameter search...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1020\n",
            "[LightGBM] [Info] Number of data points in the train set: 5964, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 35.166757\n",
            "\n",
            "Best Hyperparameters Found:\n",
            "{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 406, 'num_leaves': 26, 'subsample': 0.7}\n",
            "\n",
            "--- Evaluating Best Model ---\n",
            "MAE: 4.43\n",
            "RMSE: 8.20\n",
            "\n",
            "Tuned model saved to tuned_forecast_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MwteuwypaDs",
        "outputId": "bcea5150-e119-4dd9-d0d6-3aabb2a5bff4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Model Imports ---\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# == Option 1: Tuned SVR (with Scaling) ==\n",
        "# A pipeline first scales the data, then trains the SVR\n",
        "print(\"--- Tuning Support Vector Regressor (SVR) ---\")\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svr', SVR())\n",
        "])\n",
        "svr_param_dist = {\n",
        "    'svr__C': uniform(0.1, 100),            # Regularization parameter\n",
        "    'svr__gamma': ['scale', 'auto'] + list(np.logspace(-3, 2, 6)), # Kernel coefficient\n",
        "    'svr__kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=svr_param_dist,\n",
        "    n_iter=50, cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model5.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-y398Lmp2Z1",
        "outputId": "4cc30bfa-524b-4adb-b3a4-6c454c031840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tuning Support Vector Regressor (SVR) ---\n",
            "Starting hyperparameter search...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Model Imports ---\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "# == Option 2: Tuned MLP Regressor (Neural Network, with Scaling) ==\n",
        "print(\"--- Tuning MLP Regressor ---\")\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPRegressor(max_iter=1000, early_stopping=True, random_state=42))\n",
        "])\n",
        "mlp_param_dist = {\n",
        "    'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'mlp__activation': ['relu', 'tanh', 'logistic'],\n",
        "    'mlp__solver': ['adam'],\n",
        "    'mlp__alpha': uniform(0.0001, 0.1), # L2 penalty (regularization)\n",
        "    'mlp__learning_rate_init': uniform(0.001, 0.1)\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=mlp_param_dist,\n",
        "    n_iter=25, cv=5, verbose=1, random_state=42, n_jobs=-1 # Fewer iterations as NN can be slow\n",
        ")\n",
        "\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model6.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "id": "aKnfi38Ap-hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Model Imports ---\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# == Option 3: Tuned CatBoost Regressor ==\n",
        "print(\"--- Tuning CatBoost ---\")\n",
        "cbr_param_dist = {\n",
        "    'iterations': randint(200, 1000),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'depth': randint(4, 10),\n",
        "    'l2_leaf_reg': randint(1, 10) # L2 regularization\n",
        "}\n",
        "# CatBoost can be verbose, so silent=True is helpful\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=CatBoostRegressor(random_state=42, verbose=0),\n",
        "    param_distributions=cbr_param_dist,\n",
        "    n_iter=50, cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model7.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "id": "Gy_TgV7UqDzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Model Imports ---\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load your dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"air_quality_forecast_dataset.csv\")\n",
        "\n",
        "# Ensure numeric and no missing values\n",
        "df = df.dropna()\n",
        "for col in ['pm25_current', 'temperature', 'humidity', 'precipitation']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Split data\n",
        "# -------------------------------\n",
        "X = df[['pm25_current', 'temperature', 'humidity', 'precipitation']]\n",
        "y = df['pm25_next']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3. Hyperparameter Tuning with RandomizedSearchCV\n",
        "#    - Choose ONE of the following model sections to uncomment and run.\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# == Option 4: Tuned Scikit-learn Gradient Boosting Regressor ==\n",
        "print(\"--- Tuning Gradient Boosting ---\")\n",
        "gbr_param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'subsample': uniform(0.7, 0.3) # 0.3 here means 0.7 to 1.0\n",
        "}\n",
        "model_tuner = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingRegressor(random_state=42),\n",
        "    param_distributions=gbr_param_dist,\n",
        "    n_iter=50, cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "# Fit the tuner to find the best hyperparameters\n",
        "print(\"Starting hyperparameter search...\")\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model found by the tuner\n",
        "best_model = model_tuner.best_estimator_\n",
        "print(\"\\nBest Hyperparameters Found:\")\n",
        "print(model_tuner.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate the BEST model\n",
        "# -------------------------------\n",
        "print(\"\\n--- Evaluating Best Model ---\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Save the BEST trained model\n",
        "# -------------------------------\n",
        "joblib.dump(best_model, \"tuned_forecast_model8.pkl\")\n",
        "print(\"\\nTuned model saved to tuned_forecast_model.pkl\")"
      ],
      "metadata": {
        "id": "eUzKGonkqLJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}